{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "import datetime, time, os\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "    \n",
    "print('Using TensorFlow version: %s' % tf.__version__)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import datetime, time, os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "#!pip install -q git+https://github.com/tensorflow/docs # install first time\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fafe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this command you can clear any logs from previous runs\n",
    "# If you want to compare different runs you can skip this cell \n",
    "!rm -rf my_logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a12ef62",
   "metadata": {},
   "source": [
    "## Loading the processed dataframe (sugarbeet and field weatherstation data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb56623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/isabellecarinaflaig/neuefische/capstone_project/data_strube/pickles/df_openweather_sugar_coded.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string for categorizing\n",
    "df['seednames_coded'] = df['seednames_coded'].astype(str)\n",
    "df['pollinator'] = df['pollinator'].astype(str)\n",
    "df['ms_comp'] = df['ms_comp'].astype(str)\n",
    "df['otype_comp'] = df['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc263bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns \n",
    "df.drop(['betaine_nir', \n",
    "         'cry_nir', \n",
    "         'dm_nir', \n",
    "         'invert_nir', \n",
    "         'mark_nir', \n",
    "         'sc_nir',\n",
    "         #'csy_nir', \n",
    "         'totaln_nir', \n",
    "         'obj',  \n",
    "         'seriesid', \n",
    "         'x', \n",
    "         'y', \n",
    "         'ms_comp',\n",
    "         'otype_comp', \n",
    "         #'pollinator',\n",
    "         #'seednames_coded',\n",
    "         'region',\n",
    "         'station_location'\n",
    "         ], axis=1, inplace=True)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852aa4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ec5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index after drpping columns\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7fca90",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for categorical predictors/features \n",
    "cat_features = list(df.columns[df.dtypes==object])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18542a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for numerical predictors/features\n",
    "# since 'sc_nir' is our target variable we will exclude this feature from the list of numerical predictors \n",
    "# latitude and longitude are also excluded to avoid location influence on prediction\n",
    "num_features = [\n",
    " 'dew_point_monthly_10', 'dew_point_monthly_4', 'dew_point_monthly_5',\n",
    "       'dew_point_monthly_6', 'dew_point_monthly_7', 'dew_point_monthly_8',\n",
    "       'dew_point_monthly_9', 'humidity_monthly_10', 'humidity_monthly_4',\n",
    "       'humidity_monthly_5', 'humidity_monthly_6', 'humidity_monthly_7',\n",
    "       'humidity_monthly_8', 'humidity_monthly_9', 'pressure_monthly_10',\n",
    "       'pressure_monthly_4', 'pressure_monthly_5', 'pressure_monthly_6',\n",
    "       'pressure_monthly_7', 'pressure_monthly_8', 'pressure_monthly_9',\n",
    "       'temp_max_monthly_10', 'temp_max_monthly_4', 'temp_max_monthly_5',\n",
    "       'temp_max_monthly_6', 'temp_max_monthly_7', 'temp_max_monthly_8',\n",
    "       'temp_max_monthly_9', 'temp_min_monthly_10', 'temp_min_monthly_4',\n",
    "       'temp_min_monthly_5', 'temp_min_monthly_6', 'temp_min_monthly_7',\n",
    "       'temp_min_monthly_8', 'temp_min_monthly_9', 'temp_monthly_10',\n",
    "       'temp_monthly_4', 'temp_monthly_5', 'temp_monthly_6', 'temp_monthly_7',\n",
    "       'temp_monthly_8', 'temp_monthly_9', 'wind_deg_monthly_10',\n",
    "       'wind_deg_monthly_4', 'wind_deg_monthly_5', 'wind_deg_monthly_6',\n",
    "       'wind_deg_monthly_7', 'wind_deg_monthly_8', 'wind_deg_monthly_9',\n",
    "       'wind_speed_monthly_10', 'wind_speed_monthly_4', 'wind_speed_monthly_5',\n",
    "       'wind_speed_monthly_6', 'wind_speed_monthly_7', 'wind_speed_monthly_8',\n",
    "       'wind_speed_monthly_9'\n",
    "]\n",
    "num_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e1d994",
   "metadata": {},
   "source": [
    "#### Preparing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aecf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE!!!\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423efa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X_train = df.drop('csy_nir', axis=1)\n",
    "y_train = df['csy_nir']\n",
    "print(f\"We have {X_train.shape[0]} observations in our dataset and {X_train.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y_train.shape[0]} values\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80d37650",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29168ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b44399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb89fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete pipeline for numerical features\n",
    "# apply transformers to numerical pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "], sparse_threshold=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a38ac03",
   "metadata": {},
   "source": [
    "#### Transform X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.shape\n",
    "\n",
    "X_tf_train = tf.convert_to_tensor(X_train_transformed)\n",
    "y_tf_train = tf.convert_to_tensor(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26098865",
   "metadata": {},
   "source": [
    "## Training\n",
    "For training you need a train/val split (hopefully you did a train/test split before (and you should use the same as in your ML project to make results comparable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionary to store results\n",
    "training_history = {}\n",
    "\n",
    "# define number of epochs and learning rate decay\n",
    "N_TRAIN = len(X_train)\n",
    "N_VAL = 0.2\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = N_TRAIN // 10\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "# lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "#     0.001,\n",
    "#     decay_steps=STEPS_PER_EPOCH*1000,\n",
    "#     decay_rate=1,\n",
    "#     staircase=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afda48b9",
   "metadata": {},
   "source": [
    "### Build, compile and fit your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path for new directory \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "# define function for creating a new folder for each run\n",
    "def get_run_logdir():\n",
    "    now = datetime.now()\n",
    "    run_id = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0728de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path where checkpoints should be stored\n",
    "checkpoint_path = \"training_1/ML_model.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0) # Set verbose != 0 if you want output during training \n",
    "# return [list of your callbacks]\n",
    "def get_callbacks(name):\n",
    "    return tf.keras.callbacks.TensorBoard(run_logdir+name, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcdd8a",
   "metadata": {},
   "source": [
    "You can implement your callbacks in the `model.fit()` method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile_and_fit(model, name, optimizer=None, max_epochs=EPOCHS):\n",
    "  \n",
    "    # model.compile\n",
    "    model.compile(optimizer = 'adam', loss = 'mae', metrics = ['mse'])\n",
    "    \n",
    "    # model.fit\n",
    "    history = model.fit(X_tf_train, y_train, batch_size = BATCH_SIZE, validation_split=N_VAL, epochs = max_epochs, callbacks=get_callbacks(name))\n",
    "    \n",
    "    # return results\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436f486",
   "metadata": {},
   "source": [
    "#### Build your model\n",
    "You can build your model by using `tf.keras.Sequential()` that helps you to sequentially define your different layers from input to output. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9e5d271",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535bfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31056e5",
   "metadata": {},
   "source": [
    "#### Train your model\n",
    "Train your model by using your `model_compile_and_fit()` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_tf_train,y_tf_train):\n",
    "\n",
    "#your_history = model_compile_and_fit(your_model, ....)\n",
    "    with tf.device('/cpu:0'):\n",
    "        training_history[\"first_model\"] = model_compile_and_fit(model, \"first_model\")\n",
    "#         scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0e282",
   "metadata": {},
   "source": [
    "#### Evaluate your model training\n",
    "TensorFlow offers now (this was more cumbersome before) a simple history plotter that you can use to plot training histories and see how the model performed on training and validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5623bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function for MSE\n",
    "def plot_metric(history):\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.ylim([0, 2.5])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c383836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(training_history['first_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function for loss\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 5])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_history['first_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter = tfdocs.plots.HistoryPlotter(metric = 'mse', smoothing_std=10)\n",
    "history_plotter.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c71cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen = pd.read_pickle('/Users/isabellecarinaflaig/neuefische/capstone_project/data_strube/pickles/weatherprediction.pkl')\n",
    "df_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen['seednames_coded'] = df_unseen['seednames_coded'].astype(str)\n",
    "df_unseen['pollinator'] = df_unseen['pollinator'].astype(str)\n",
    "df_unseen['ms_comp'] = df_unseen['ms_comp'].astype(str)\n",
    "df_unseen['otype_comp'] = df_unseen['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ebbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X_test = df_unseen\n",
    "print(f\"We have {X_test.shape[0]} observations in our dataset and {X_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508662ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "X_tf_test = tf.convert_to_tensor(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3261a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_tf_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10582968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for output\n",
    "data = {'seednames_coded': df_unseen.seednames_coded, 'predicted_sugar_content': y_predicted, 'weather_station': df_unseen.station_location, 'pollinator': df_unseen.pollinator, 'otype': df_unseen.otype_comp, 'ms': df_unseen.ms_comp}\n",
    "output_table = pd.DataFrame(data)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.to_csv('prediction_sugar_content_dnn_model_1_csy.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85938cce",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "926e2e1b",
   "metadata": {},
   "source": [
    "## Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3acc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# Second Model with more nodes\n",
    "#===========#\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])  \n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_tf_train,y_tf_train):\n",
    "#your_history = model_compile_and_fit(your_model, ....)\n",
    "    with tf.device('/cpu:0'):\n",
    "        training_history[\"second_model\"] = model_compile_and_fit(model, \"second_model\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(training_history['second_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be75b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_history['second_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa43a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter = tfdocs.plots.HistoryPlotter(metric = 'mse', smoothing_std=10)\n",
    "history_plotter.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_tf_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for output\n",
    "data = {'seednames_coded': df_unseen.seednames_coded, 'predicted_sugar_content': y_predicted, 'weather_station': df_unseen.station_location, 'pollinator': df_unseen.pollinator, 'otype': df_unseen.otype_comp, 'ms': df_unseen.ms_comp}\n",
    "output_table = pd.DataFrame(data)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e68b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.to_csv('prediction_sugar_content_dnn_model_2_csy.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7469da8",
   "metadata": {},
   "source": [
    "## Third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c86ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# Third Model with more layers\n",
    "#===========#\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        # layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])  \n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_tf_train,y_tf_train):\n",
    "\n",
    "#your_history = model_compile_and_fit(your_model, ....)\n",
    "    with tf.device('/cpu:0'):\n",
    "        training_history[\"third_model\"] = model_compile_and_fit(model, \"third_model\")\n",
    "\n",
    "model.summary()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc45f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(training_history['third_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_history['third_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter = tfdocs.plots.HistoryPlotter(metric = 'mse', smoothing_std=10)\n",
    "history_plotter.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061877f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5340430",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_tf_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff14afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for output\n",
    "data = {'seednames_coded': df_unseen.seednames_coded, 'predicted_sugar_content': y_predicted, 'weather_station': df_unseen.station_location, 'pollinator': df_unseen.pollinator, 'otype': df_unseen.otype_comp, 'ms': df_unseen.ms_comp}\n",
    "output_table = pd.DataFrame(data)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.to_csv('prediction_sugar_content_dnn_model_3_csy.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e4590f",
   "metadata": {},
   "source": [
    "## Fourth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# Fourth Model with dropout\n",
    "#===========#\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])  \n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_tf_train,y_tf_train):\n",
    "\n",
    "#your_history = model_compile_and_fit(your_model, ....)\n",
    "    with tf.device('/cpu:0'):\n",
    "        training_history[\"fourth_model\"] = model_compile_and_fit(model, \"fourth_model\")\n",
    "\n",
    "model.summary()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(training_history['fourth_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cbe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_history['fourth_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter = tfdocs.plots.HistoryPlotter(metric = 'mse', smoothing_std=10)\n",
    "history_plotter.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d676da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_tf_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f74f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for output\n",
    "data = {'seednames_coded': df_unseen.seednames_coded, 'predicted_sugar_content': y_predicted, 'weather_station': df_unseen.station_location, 'pollinator': df_unseen.pollinator, 'otype': df_unseen.otype_comp, 'ms': df_unseen.ms_comp}\n",
    "output_table = pd.DataFrame(data)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8195b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.to_csv('prediction_sugar_content_dnn_model_4_csy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6005"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "61433a13eba5a829a1dfb9a19c2018b676dc6600a268347de5770ba407739072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
