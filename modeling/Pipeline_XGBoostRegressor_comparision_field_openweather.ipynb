{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import  mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# import functions\n",
    "from src.modeling.modeling_functions import error_analysis\n",
    "from src.preprocessing.preprocessing_functions import drop_rows\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # change decimal places\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the processed dataframe (sugarbeet and field weatherstation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pickles/df_fieldweather_devstage_sugarbeet.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string for categorizing\n",
    "df['seednames_coded'] = df['seednames_coded'].astype(str)\n",
    "df['pollinator_comp'] = df['pollinator_comp'].astype(str)\n",
    "df['ms_comp'] = df['ms_comp'].astype(str)\n",
    "df['otype_comp'] = df['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.station_location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop locations for comparison\n",
    "drop_rows(df, 'station_location', ['Bautzen', 'Goderville', 'Lamotte', 'Lelystad', 'Pithiviers', \n",
    "                                   'Rittershausen', 'Sommepy', 'Vierhoefen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns \n",
    "df.drop(['betaine_nir', \n",
    "         'cry_nir', \n",
    "         'dm_nir', \n",
    "         'invert_nir', \n",
    "         'mark_nir', \n",
    "         #'sc_nir',\n",
    "         'csy_nir', \n",
    "         'totaln_nir',\n",
    "         'obj',  \n",
    "         'seriesid', \n",
    "         'x', \n",
    "         'y', \n",
    "         'ms_comp',\n",
    "         'otype_comp', \n",
    "         #'pollinator_comp',\n",
    "         #'seednames_coded',\n",
    "         'region',\n",
    "         'station_location'\n",
    "         ], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index after drpping columns\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for categorical predictors/features \n",
    "cat_features = list(df.columns[df.dtypes==object])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for numerical predictors/features\n",
    "# since 'sc_nir' is our target variable we will exclude this feature from the list of numerical predictors \n",
    "# latitude and longitude are also excluded to avoid location influence on prediction\n",
    "num_features = [\n",
    " 'air_temperature_avg_devstage_1',\n",
    " 'air_temperature_avg_devstage_2',\n",
    " 'air_temperature_avg_devstage_3',\n",
    " 'air_temperature_max_devstage_1',\n",
    " 'air_temperature_max_devstage_2',\n",
    " 'air_temperature_max_devstage_3',\n",
    " 'air_temperature_min_devstage_1',\n",
    " 'air_temperature_min_devstage_2',\n",
    " 'air_temperature_min_devstage_3',\n",
    " 'deltat_avg_devstage_1',\n",
    " 'deltat_avg_devstage_2',\n",
    " 'deltat_avg_devstage_3',\n",
    " 'deltat_max_devstage_1',\n",
    " 'deltat_max_devstage_2',\n",
    " 'deltat_max_devstage_3',\n",
    " 'deltat_min_devstage_1',\n",
    " 'deltat_min_devstage_2',\n",
    " 'deltat_min_devstage_3',\n",
    " 'dew_point_avg_devstage_1',\n",
    " 'dew_point_avg_devstage_2',\n",
    " 'dew_point_avg_devstage_3',\n",
    " 'dew_point_min_devstage_1',\n",
    " 'dew_point_min_devstage_2',\n",
    " 'dew_point_min_devstage_3',\n",
    " 'eag_soil_moisture_1_devstage_1',\n",
    " 'eag_soil_moisture_1_devstage_2',\n",
    " 'eag_soil_moisture_1_devstage_3',\n",
    " 'eag_soil_moisture_2_devstage_1',\n",
    " 'eag_soil_moisture_2_devstage_2',\n",
    " 'eag_soil_moisture_2_devstage_3',\n",
    " 'eag_soil_moisture_3_devstage_1',\n",
    " 'eag_soil_moisture_3_devstage_2',\n",
    " 'eag_soil_moisture_3_devstage_3',\n",
    " 'eag_soil_moisture_4_devstage_1',\n",
    " 'eag_soil_moisture_4_devstage_2',\n",
    " 'eag_soil_moisture_4_devstage_3',\n",
    " 'eag_soil_moisture_5_devstage_1',\n",
    " 'eag_soil_moisture_5_devstage_2',\n",
    " 'eag_soil_moisture_5_devstage_3',\n",
    " 'eag_soil_moisture_6_devstage_1',\n",
    " 'eag_soil_moisture_6_devstage_2',\n",
    " 'eag_soil_moisture_6_devstage_3',\n",
    " 'et0_devstage_1',\n",
    " 'et0_devstage_2',\n",
    " 'et0_devstage_3',\n",
    "#  'latitude_1',\n",
    "#  'latitude_2',\n",
    "#  'latitude_3',\n",
    " 'leaf_wetness_devstage_1',\n",
    " 'leaf_wetness_devstage_2',\n",
    " 'leaf_wetness_devstage_3',\n",
    "#  'longitude_1',\n",
    "#  'longitude_2',\n",
    "#  'longitude_3',\n",
    " 'precipitation_devstage_1',\n",
    " 'precipitation_devstage_2',\n",
    " 'precipitation_devstage_3',\n",
    " 'relative_humidity_avg_devstage_1',\n",
    " 'relative_humidity_avg_devstage_2',\n",
    " 'relative_humidity_avg_devstage_3',\n",
    " 'relative_humidity_max_devstage_1',\n",
    " 'relative_humidity_max_devstage_2',\n",
    " 'relative_humidity_max_devstage_3',\n",
    " 'relative_humidity_min_devstage_1',\n",
    " 'relative_humidity_min_devstage_2',\n",
    " 'relative_humidity_min_devstage_3',\n",
    " 'saturation_vpd_avg_devstage_1',\n",
    " 'saturation_vpd_avg_devstage_2',\n",
    " 'saturation_vpd_avg_devstage_3',\n",
    " 'saturation_vpd_min_devstage_1',\n",
    " 'saturation_vpd_min_devstage_2',\n",
    " 'saturation_vpd_min_devstage_3',\n",
    " 'soil_salinity_1_devstage_1',\n",
    " 'soil_salinity_1_devstage_2',\n",
    " 'soil_salinity_1_devstage_3',\n",
    " 'soil_salinity_2_devstage_1',\n",
    " 'soil_salinity_2_devstage_2',\n",
    " 'soil_salinity_2_devstage_3',\n",
    " 'soil_salinity_3_devstage_1',\n",
    " 'soil_salinity_3_devstage_2',\n",
    " 'soil_salinity_3_devstage_3',\n",
    " 'soil_salinity_4_devstage_1',\n",
    " 'soil_salinity_4_devstage_2',\n",
    " 'soil_salinity_4_devstage_3',\n",
    " 'soil_salinity_5_devstage_1',\n",
    " 'soil_salinity_5_devstage_2',\n",
    " 'soil_salinity_5_devstage_3',\n",
    " 'soil_salinity_6_devstage_1',\n",
    " 'soil_salinity_6_devstage_2',\n",
    " 'soil_salinity_6_devstage_3',\n",
    " 'soil_temperature_1_max_devstage_1',\n",
    " 'soil_temperature_1_max_devstage_2',\n",
    " 'soil_temperature_1_max_devstage_3',\n",
    " 'soil_temperature_1_min_devstage_1',\n",
    " 'soil_temperature_1_min_devstage_2',\n",
    " 'soil_temperature_1_min_devstage_3',\n",
    " 'soil_temperature_1_vg_devstage_1',\n",
    " 'soil_temperature_1_vg_devstage_2',\n",
    " 'soil_temperature_1_vg_devstage_3',\n",
    " 'soil_temperature_2_max_devstage_1',\n",
    " 'soil_temperature_2_max_devstage_2',\n",
    " 'soil_temperature_2_max_devstage_3',\n",
    " 'soil_temperature_2_min_devstage_1',\n",
    " 'soil_temperature_2_min_devstage_2',\n",
    " 'soil_temperature_2_min_devstage_3',\n",
    " 'soil_temperature_2_vg_devstage_1',\n",
    " 'soil_temperature_2_vg_devstage_2',\n",
    " 'soil_temperature_2_vg_devstage_3',\n",
    " 'soil_temperature_3_max_devstage_1',\n",
    " 'soil_temperature_3_max_devstage_2',\n",
    " 'soil_temperature_3_max_devstage_3',\n",
    " 'soil_temperature_3_min_devstage_1',\n",
    " 'soil_temperature_3_min_devstage_2',\n",
    " 'soil_temperature_3_min_devstage_3',\n",
    " 'soil_temperature_3_vg_devstage_1',\n",
    " 'soil_temperature_3_vg_devstage_2',\n",
    " 'soil_temperature_3_vg_devstage_3',\n",
    " 'soil_temperature_4_max_devstage_1',\n",
    " 'soil_temperature_4_max_devstage_2',\n",
    " 'soil_temperature_4_max_devstage_3',\n",
    " 'soil_temperature_4_min_devstage_1',\n",
    " 'soil_temperature_4_min_devstage_2',\n",
    " 'soil_temperature_4_min_devstage_3',\n",
    " 'soil_temperature_4_vg_devstage_1',\n",
    " 'soil_temperature_4_vg_devstage_2',\n",
    " 'soil_temperature_4_vg_devstage_3',\n",
    " 'soil_temperature_5_max_devstage_1',\n",
    " 'soil_temperature_5_max_devstage_2',\n",
    " 'soil_temperature_5_max_devstage_3',\n",
    " 'soil_temperature_5_min_devstage_1',\n",
    " 'soil_temperature_5_min_devstage_2',\n",
    " 'soil_temperature_5_min_devstage_3',\n",
    " 'soil_temperature_5_vg_devstage_1',\n",
    " 'soil_temperature_5_vg_devstage_2',\n",
    " 'soil_temperature_5_vg_devstage_3',\n",
    " 'soil_temperature_6_max_devstage_1',\n",
    " 'soil_temperature_6_max_devstage_2',\n",
    " 'soil_temperature_6_max_devstage_3',\n",
    " 'soil_temperature_6_min_devstage_1',\n",
    " 'soil_temperature_6_min_devstage_2',\n",
    " 'soil_temperature_6_min_devstage_3',\n",
    " 'soil_temperature_6_vg_devstage_1',\n",
    " 'soil_temperature_6_vg_devstage_2',\n",
    " 'soil_temperature_6_vg_devstage_3',\n",
    " 'solar_radiation_devstage_1',\n",
    " 'solar_radiation_devstage_2',\n",
    " 'solar_radiation_devstage_3',\n",
    " 'wind_direction_devstage_1',\n",
    " 'wind_direction_devstage_2',\n",
    " 'wind_direction_devstage_3',\n",
    " 'wind_speed_avg_devstage_1',\n",
    " 'wind_speed_avg_devstage_2',\n",
    " 'wind_speed_avg_devstage_3',\n",
    " 'wind_speed_gusts_devstage_1',\n",
    " 'wind_speed_gusts_devstage_2',\n",
    " 'wind_speed_gusts_devstage_3',\n",
    " 'wind_speed_max_devstage_1',\n",
    " 'wind_speed_max_devstage_2',\n",
    " 'wind_speed_max_devstage_3'\n",
    "]\n",
    "num_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X = df.drop('sc_nir', axis=1)\n",
    "y = df['sc_nir']\n",
    "print(f\"We have {X.shape[0]} observations in our dataset and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set (train set: 70%, test set: 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RSEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete pipeline for numerical features\n",
    "# apply transformers to numerical pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling using Pipeline and GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a full pipeline with our preprocessor and the RandomForestRegressor\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "# cross_val_predict expects an estimator (model), X, y and number of cv-splits (cv)\n",
    "y_train_predicted = cross_val_predict(pipe, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "print('MSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted, squared = False))\n",
    "\n",
    "# R^2 Score\n",
    "print('R^2 XGBoost Train:\\n', r2_score(y_train, y_train_predicted))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter space for grid-search\n",
    "# add 'xgb__' infront of the corresponding hyperparameters\n",
    "param = {'xgb__max_depth': [10,20,30,40,50],\n",
    "                  'xgb__max_features': [\"sqrt\"],\n",
    "                  'xgb__max_leaf_nodes': [500, 5000],\n",
    "                  'xgb__min_samples_split': [10, 50, 100]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring = r2_score, cv=5,\n",
    "                           verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model (including fitted preprocessing steps) as best_model \n",
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean squared error, root mean squared error and r^2 score for the test set with the optimized model\n",
    "y_test_predicted = best_model.predict(X_test)\n",
    "\n",
    "# Mean Squared Error\n",
    "print('MSE XGBoost Test:\\n', mean_squared_error(y_test, y_test_predicted))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE XGBoost Test:\\n', mean_squared_error(y_test, y_test_predicted, squared = False))\n",
    "\n",
    "# R^2 Score\n",
    "print('R^2 XGBoost Test:\\n', r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the error\n",
    "error_analysis(y_test,y_test_predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipe with train data\n",
    "model = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coefficients\n",
    "coefs = model.steps[1][1].feature_importances_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "feature_names = model.steps[0][1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(feature_names, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"#2f7055\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_field = df\n",
    "zipped_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_field.to_csv('XGBoost_field_coefficients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(5),\n",
    "           palette=df.head(5)[\"colors\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top 5 Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the processed dataframe (sugarbeet and openweather weatherstation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pickles/df_openweather_devstage_sugarbeet.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string for categorizing\n",
    "df['seednames_coded'] = df['seednames_coded'].astype(str)\n",
    "df['pollinator_comp'] = df['pollinator_comp'].astype(str)\n",
    "df['ms_comp'] = df['ms_comp'].astype(str)\n",
    "df['otype_comp'] = df['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.station_location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop locations for comparison\n",
    "drop_rows(df, 'station_location', ['Bautzen', 'Goderville', 'Lamotte', 'Lelystad', 'Pithiviers', \n",
    "                                   'Rittershausen', 'Sommepy', 'Vierhoefen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns \n",
    "df.drop(['betaine_nir', \n",
    "         'cry_nir', \n",
    "         'dm_nir', \n",
    "         'invert_nir', \n",
    "         'mark_nir', \n",
    "         #'sc_nir',\n",
    "         'csy_nir', \n",
    "         'totaln_nir',\n",
    "         'obj',  \n",
    "         'seriesid', \n",
    "         'x', \n",
    "         'y', \n",
    "         'ms_comp',\n",
    "         'otype_comp', \n",
    "         #'pollinator_comp',\n",
    "         #'seednames_coded',\n",
    "         'region',\n",
    "         'station_location'\n",
    "         ], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index after drpping columns\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for categorical predictors/features \n",
    "cat_features = list(df.columns[df.dtypes==object])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for numerical predictors/features\n",
    "# since 'sc_nir' is our target variable we will exclude this feature from the list of numerical predictors \n",
    "# latitude and longitude were previously excluded to avoid location influence on prediction\n",
    "num_features = [\n",
    " 'dew_point_dev_stage_1', \n",
    " 'dew_point_dev_stage_2',\n",
    " 'dew_point_dev_stage_3', \n",
    " 'humidity_dev_stage_1', \n",
    " 'humidity_dev_stage_2',\n",
    " 'humidity_dev_stage_3', \n",
    " 'pressure_dev_stage_1', \n",
    " 'pressure_dev_stage_2',\n",
    " 'pressure_dev_stage_3', \n",
    " 'temp_dev_stage_1', \n",
    " 'temp_dev_stage_2',\n",
    " 'temp_dev_stage_3', \n",
    " 'temp_max_dev_stage_1', \n",
    " 'temp_max_dev_stage_2',\n",
    " 'temp_max_dev_stage_3', \n",
    " 'temp_min_dev_stage_1', \n",
    " 'temp_min_dev_stage_2',\n",
    " 'temp_min_dev_stage_3', \n",
    " 'wind_deg_dev_stage_1', \n",
    " 'wind_deg_dev_stage_2',\n",
    " 'wind_deg_dev_stage_3',\n",
    " 'wind_speed_dev_stage_1',\n",
    " 'wind_speed_dev_stage_2', \n",
    " 'wind_speed_dev_stage_3'\n",
    "]\n",
    "num_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trian-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X = df.drop('sc_nir', axis=1)\n",
    "y = df['sc_nir']\n",
    "print(f\"We have {X.shape[0]} observations in our dataset and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set (train set: 70%, test set: 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RSEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete pipeline for numerical features\n",
    "# apply transformers to numerical pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling using Pipeline and GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a full pipeline with our preprocessor and the RandomForestRegressor\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "# cross_val_predict expects an estimator (model), X, y and number of cv-splits (cv)\n",
    "y_train_predicted = cross_val_predict(pipe, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "print('MSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted, squared = False))\n",
    "\n",
    "# R^2 Score\n",
    "print('R^2 XGBoost Train:\\n', r2_score(y_train, y_train_predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter space for grid-search\n",
    "# add 'randomforest__' infront of the corresponding hyperparameters\n",
    "param = {'xgb__max_depth': [10,20,30,40,50],\n",
    "                  'xgb__max_features': [\"sqrt\"],\n",
    "                  'xgb__max_leaf_nodes': [500, 5000],\n",
    "                  'xgb__min_samples_split': [10, 50, 100]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring = r2_score, cv=5,\n",
    "                           verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model (including fitted preprocessing steps) as best_model \n",
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean squared error, root mean squared error and r^2 score for the test set with the optimized model\n",
    "y_test_predicted = best_model.predict(X_test)\n",
    "\n",
    "# Mean Squared Error\n",
    "print('MSE XGBoost Test:\\n', mean_squared_error(y_test, y_test_predicted))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE XGBoost Test:\\n', mean_squared_error(y_test, y_test_predicted, squared = False))\n",
    "\n",
    "# R^2 Score\n",
    "print('R^2 XGBoost Test:\\n', r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the error\n",
    "error_analysis(y_test,y_test_predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipe with train data\n",
    "model = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coefficients\n",
    "coefs = model.steps[1][1].feature_importances_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "feature_names = model.steps[0][1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(feature_names, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"#2f7055\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_openweather = df\n",
    "zipped_openweather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_openweather.to_csv('XGBoost_openweather_coefficients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(5),\n",
    "           palette=df.head(5)[\"colors\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top 5 Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Diabetes-Challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e059eaba76b2a6e1a2c31f90124418260e93f5f5794c3ff5e8e76706cac962e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
