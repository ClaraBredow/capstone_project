{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import  mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# import functions\n",
    "from src.modeling.modeling_functions import error_analysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # change decimal places\n",
    "\n",
    "RSEED = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the processed dataframe (sugarbeet and openweather station data - all fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = pd.read_pickle('pickles/df_openweather_monthly_sugarbeet.pkl')\n",
    "df_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.station_location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string for categorizing\n",
    "df_og['seednames_coded'] = df_og['seednames_coded'].astype(str)\n",
    "df_og['pollinator_comp'] = df_og['pollinator_comp'].astype(str)\n",
    "df_og['ms_comp'] = df_og['ms_comp'].astype(str)\n",
    "df_og['otype_comp'] = df_og['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og\n",
    "# dropping columns \n",
    "df.drop(['betaine_nir', \n",
    "         'cry_nir', \n",
    "         'dm_nir', \n",
    "         'invert_nir', \n",
    "         'mark_nir', \n",
    "         'sc_nir',\n",
    "         #'csy_nir', \n",
    "         'totaln_nir', \n",
    "         'obj',  \n",
    "         'seriesid', \n",
    "         'x', \n",
    "         'y', \n",
    "         'ms_comp',\n",
    "         'otype_comp', \n",
    "         #'pollinator_comp',\n",
    "         #'seednames_coded',\n",
    "         'region',\n",
    "         'station_location'\n",
    "         ], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index after drpping columns\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for categorical predictors/features \n",
    "cat_features = list(df.columns[df.dtypes==object])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for numerical predictors/features\n",
    "# since 'sc_nir' is our target variable we will exclude this feature from the list of numerical predictors \n",
    "# latitude and longitude are also excluded to avoid location influence on prediction\n",
    "num_features = [\n",
    " 'dew_point_monthly_10.0',\n",
    " 'dew_point_monthly_4.0',\n",
    " 'dew_point_monthly_5.0',\n",
    " 'dew_point_monthly_6.0',\n",
    " 'dew_point_monthly_7.0',\n",
    " 'dew_point_monthly_8.0',\n",
    " 'dew_point_monthly_9.0',\n",
    " 'humidity_monthly_10.0',\n",
    " 'humidity_monthly_4.0',\n",
    " 'humidity_monthly_5.0',\n",
    " 'humidity_monthly_6.0',\n",
    " 'humidity_monthly_7.0',\n",
    " 'humidity_monthly_8.0',\n",
    " 'humidity_monthly_9.0',\n",
    " 'pressure_monthly_10.0',\n",
    " 'pressure_monthly_4.0',\n",
    " 'pressure_monthly_5.0',\n",
    " 'pressure_monthly_6.0',\n",
    " 'pressure_monthly_7.0',\n",
    " 'pressure_monthly_8.0',\n",
    " 'pressure_monthly_9.0',\n",
    " 'temp_max_monthly_10.0',\n",
    " 'temp_max_monthly_4.0',\n",
    " 'temp_max_monthly_5.0',\n",
    " 'temp_max_monthly_6.0',\n",
    " 'temp_max_monthly_7.0',\n",
    " 'temp_max_monthly_8.0',\n",
    " 'temp_max_monthly_9.0',\n",
    " 'temp_min_monthly_10.0',\n",
    " 'temp_min_monthly_4.0',\n",
    " 'temp_min_monthly_5.0',\n",
    " 'temp_min_monthly_6.0',\n",
    " 'temp_min_monthly_7.0',\n",
    " 'temp_min_monthly_8.0',\n",
    " 'temp_min_monthly_9.0',\n",
    " 'temp_monthly_10.0',\n",
    " 'temp_monthly_4.0',\n",
    " 'temp_monthly_5.0',\n",
    " 'temp_monthly_6.0',\n",
    " 'temp_monthly_7.0',\n",
    " 'temp_monthly_8.0',\n",
    " 'temp_monthly_9.0',\n",
    " 'wind_deg_monthly_10.0',\n",
    " 'wind_deg_monthly_4.0',\n",
    " 'wind_deg_monthly_5.0',\n",
    " 'wind_deg_monthly_6.0',\n",
    " 'wind_deg_monthly_7.0',\n",
    " 'wind_deg_monthly_8.0',\n",
    " 'wind_deg_monthly_9.0',\n",
    " 'wind_speed_monthly_10.0',\n",
    " 'wind_speed_monthly_4.0',\n",
    " 'wind_speed_monthly_5.0',\n",
    " 'wind_speed_monthly_6.0',\n",
    " 'wind_speed_monthly_7.0',\n",
    " 'wind_speed_monthly_8.0',\n",
    " 'wind_speed_monthly_9.0'\n",
    "]\n",
    "num_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE!!!\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X_train = df.drop('csy_nir', axis=1)\n",
    "y_train = df['csy_nir']\n",
    "print(f\"We have {X_train.shape[0]} observations in our dataset and {X_train.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y_train.shape[0]} values\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete pipeline for numerical features\n",
    "# apply transformers to numerical pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling using Pipeline and GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a full pipeline with our preprocessor and the RandomForestRegressor\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "# cross_val_predict expects an estimator (model), X, y and number of cv-splits (cv)\n",
    "y_train_predicted = cross_val_predict(pipe, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "print('MSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE XGBoost Train:\\n', mean_squared_error(y_train, y_train_predicted, squared = False))\n",
    "\n",
    "# R^2 Score\n",
    "print('R^2 XGBoost Train:\\n', r2_score(y_train, y_train_predicted))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter space for grid-search\n",
    "# add 'xgb__' infront of the corresponding hyperparameters\n",
    "param = {'xgb__max_depth': [10,20,30,40,50],\n",
    "                  'xgb__max_features': [\"sqrt\"],\n",
    "                  'xgb__max_leaf_nodes': [500, 5000],\n",
    "                  'xgb__min_samples_split': [10, 50, 100]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring = r2_score, cv=5,\n",
    "                           verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model (including fitted preprocessing steps) as best_model \n",
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen = pd.read_pickle('pickles/weatherprediction.pkl')\n",
    "df_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen['seednames_coded'] = df_unseen['seednames_coded'].astype(str)\n",
    "df_unseen['pollinator'] = df_unseen['pollinator'].astype(str)\n",
    "df_unseen['ms_comp'] = df_unseen['ms_comp'].astype(str)\n",
    "df_unseen['otype_comp'] = df_unseen['otype_comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictors and target variable\n",
    "X_test = df_unseen\n",
    "print(f\"We have {X_test.shape[0]} observations in our dataset and {X_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean squared error, root mean squared error and r^2 score for the test set with the optimized model\n",
    "y_predicted = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for output\n",
    "data = {'seednames_coded': df_unseen.seednames_coded, 'predicted_sugar_content': y_predicted, 'weather_station': df_unseen.station_location, 'pollinator': df_unseen.pollinator, 'otype': df_unseen.otype_comp, 'ms': df_unseen.ms_comp}\n",
    "output_table = pd.DataFrame(data)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.to_csv('data/prediction_sugar_content_table_csy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output =output_table.groupby(['seednames_coded'])['weather_station'].value_counts()\n",
    "#['predicted_sugar_content', 'actual_sugar_content'].mean()\n",
    "df_output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Diabetes-Challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8 (main, Jan  9 2023, 15:30:06) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e059eaba76b2a6e1a2c31f90124418260e93f5f5794c3ff5e8e76706cac962e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
