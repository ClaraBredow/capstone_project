{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta, timezone\n",
    "import dateutil.parser as parser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field data Sugarbeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the CSV file provided by the company\n",
    "df_sugarbeet = pd.read_csv('data/DatenfürGina_recorded2.csv', decimal=',', delimiter=';')\n",
    "# change the remaining column names to lowercase for easier use later on\n",
    "df_sugarbeet.columns = df_sugarbeet.columns.str.lower()\n",
    "\n",
    "# rename some of the columns\n",
    "df_sugarbeet.rename(columns={'ginams!': 'ms_comp', 'ginaotype!': 'otype_comp', 'ginapoll!': 'pollinator_comp', 'ginaseednames!': 'seednames_coded', 'fieldid': 'station_location'}, inplace=True)\n",
    "\n",
    "#remove the numbers from the fieldid\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'1', r'', regex=True)\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'_2', r'', regex=True)\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'2', r'', regex=True)\n",
    "#drop the columns with unnecessary information after discussion with the stakeholder\n",
    "df_sugarbeet.drop(['cropid','bm', 'breedid', 'locationid', 'fieldblock', 'fieldsubblock', 'filler',\n",
    "       'labnr', 'layoutnr','plotid', 'plotindex', 'rep','spectraname', 'trial', 'year', 'anzahl', 'standardind'], axis=1, inplace=True)\n",
    "#remove one outlier with negative value\n",
    "df_sugarbeet = df_sugarbeet[df_sugarbeet.betaine_nir >= 0]\n",
    "#exclude missing value (0.19 %)\n",
    "df_sugarbeet = df_sugarbeet.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change region names to english\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Niederlande', r'Netherlands', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Franken', r'Franconia', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Niederbayern', r'Lower_Bavaria', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Südfrankreich', r'Southern_France', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Ostdeutschland', r'Eastern_Germany', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Nordrheinwestfalen', r'NRW', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Normandie', r'Normandy', regex=True)\n",
    "df_sugarbeet['region'] = df_sugarbeet['region'].replace(r'Norddeutschland', r'Northern_Germany', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# only use when working with field weather stations\n",
    "#replace stations locations to use the correct field weather information, based on discussion with stakeholder\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'Hamm', r'Soest', regex=True)\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'Oberviehhausen', r'Mattenkofen', regex=True)\n",
    "df_sugarbeet['station_location'] = df_sugarbeet['station_location'].replace(r'Vierhöfen', r'Mattenkofen', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather data fieldstations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weather data, rename the columns in english and at the same time rename Unnamed1 to country and location to station-location\n",
    "weather_column_names = (['station_location', 'country', 'Date_time', 'Day', 'Month', 'Year', 'Hour', 'air_temperature_avg', 'air_temperature_max', 'air_temperature_min',\n",
    "                        'dew_point_avg', 'dew_point_min', 'solar_radiation', 'saturation_VPD_avg', 'saturation_VPD_min', 'relative_humidity_avg',\n",
    "                        'relative_humidity_max', 'relative_humidity_min', 'precipitation', 'leaf_wetness', 'wind_speed_avg', 'wind_speed_max', 'wind_speed_gusts',\n",
    "                        'wind_direction', 'EAG_soil_moisture_1', 'EAG_soil_moisture_2', 'EAG_soil_moisture_3', 'EAG_soil_moisture_4', 'EAG_soil_moisture_5', 'EAG_soil_moisture_6',\n",
    "                        'soil_salinity_1', 'soil_salinity_2', 'soil_salinity_3', 'soil_salinity_4', 'soil_salinity_5', 'soil_salinity_6', 'soil_temperature_1_vg', 'soil_temperature_1_max',\n",
    "                        'soil_temperature_1_min', 'soil_temperature_2_vg', 'soil_temperature_2_max', 'soil_temperature_2_min', 'soil_temperature_3_vg', 'soil_temperature_3_max',\n",
    "                        'soil_temperature_3_min', 'soil_temperature_4_vg', 'soil_temperature_4_max', 'soil_temperature_4_min', 'soil_temperature_5_vg', 'soil_temperature_5_max',\n",
    "                        'soil_temperature_5_min', 'soil_temperature_6_vg', 'soil_temperature_6_max', 'soil_temperature_6_min', 'solar_panel', 'battery',\n",
    "                        'deltaT_avg', 'deltaT_max', 'deltaT_min', 'ET0'])\n",
    "# import csv file\n",
    "df_weatherstations = pd.read_csv('data/wetterdaten_all-stations_hourly.csv', delimiter=';', decimal=',', header=0, names=weather_column_names)\n",
    "#lower case the name of the columns, rename a col\n",
    "df_weatherstations.columns = df_weatherstations.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date to datetime format and extract month and day, directly changing the month and day columns\n",
    "df_weatherstations['date_time'] = pd.to_datetime(df_weatherstations['date_time'], yearfirst=True, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df_weatherstations['month'] = df_weatherstations['date_time'].dt.month\n",
    "df_weatherstations['day'] = df_weatherstations['date_time'].dt.day\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location and sowing/harvesting dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from CSV file\n",
    "df_locations = pd.read_csv('data/fieldid_gps_dates.csv')\n",
    "# remove ° from lat and lon information\n",
    "df_locations['latitude'] = df_locations['latitude'].replace(r'°', r'', regex=True)\n",
    "df_locations['longitude'] = df_locations['longitude'].replace(r'°', r'', regex=True)\n",
    "# in order to use the information in the lat and lon columns, first change the type to string, then to float\n",
    "df_locations['latitude'] = df_locations['latitude'].astype(str)\n",
    "df_locations['longitude'] = df_locations['longitude'].astype(str)\n",
    "# float\n",
    "df_locations['latitude'] = df_locations['latitude'].astype(float)\n",
    "df_locations['longitude'] = df_locations['longitude'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather data Openweather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load individual openweatherdata\n",
    "df_anklam = pd.read_csv(\"data/Anklam.csv\", delimiter=\",\")\n",
    "df_bautzen = pd.read_csv(\"data/Bautzen.csv\", delimiter=\",\")\n",
    "df_emmeloord = pd.read_csv(\"data/Emmeloord.csv\", delimiter=\",\")\n",
    "df_goderville = pd.read_csv(\"data/Goderville.csv\", delimiter=\",\")\n",
    "df_hamm = pd.read_csv(\"data/Hamm.csv\", delimiter=\",\")\n",
    "df_herchsheim = pd.read_csv(\"data/Herchsheim.csv\", delimiter=\",\")\n",
    "df_lamotte = pd.read_csv(\"data/Lamotte.csv\", delimiter=\",\")\n",
    "df_lelystad = pd.read_csv(\"data/Lelystad.csv\", delimiter=\",\")\n",
    "df_mattenkofen = pd.read_csv(\"data/Mattenkofen.csv\", delimiter=\",\")\n",
    "df_oberviehhausen = pd.read_csv(\"data/Oberviehhausen.csv\", delimiter=\",\")\n",
    "df_pithiviers = pd.read_csv(\"data/Pithiviers.csv\", delimiter=\",\")\n",
    "df_soest = pd.read_csv(\"data/Soest.csv\", delimiter=\",\")\n",
    "df_sommepy1 = pd.read_csv(\"data/Sommepy1.csv\", delimiter=\",\")\n",
    "df_sommepy2 = pd.read_csv(\"data/Sommepy2.csv\", delimiter=\",\")\n",
    "df_stadthagen = pd.read_csv(\"data/Stadthagen.csv\", delimiter=\",\")\n",
    "df_vierhoefen = pd.read_csv(\"data/Vierhöfen.csv\", delimiter=\",\")\n",
    "\n",
    "# combine into one dataframe\n",
    "df_openweather = pd.concat ([df_anklam,\n",
    "                            df_bautzen, \n",
    "                           df_emmeloord, \n",
    "                           df_goderville, \n",
    "                           df_hamm, \n",
    "                           df_herchsheim, \n",
    "                           df_lamotte, \n",
    "                           df_lelystad, \n",
    "                           df_mattenkofen, \n",
    "                           df_oberviehhausen, \n",
    "                           df_pithiviers, \n",
    "                           df_soest, \n",
    "                           df_sommepy1, \n",
    "                           df_sommepy2, \n",
    "                           df_stadthagen,\n",
    "                           df_vierhoefen], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split iso datetime according to the + and only keep the first (the date) in a new columns\n",
    "df_openweather['date'] = df_openweather.dt_iso.apply(lambda x: x.split('+')[0])\n",
    "\n",
    "# change the new column to datetime format\n",
    "df_openweather['date'] = pd.to_datetime(df_openweather['date'])\n",
    "\n",
    "# create additional columns for year, month, and day in addition to a plottingdate counting the day of the year\n",
    "df_openweather['year'] = df_openweather['date'].dt.year\n",
    "df_openweather['month'] = df_openweather['date'].dt.month\n",
    "df_openweather['day'] = df_openweather['date'].dt.day\n",
    "df_openweather['plotting_date'] = df_openweather['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df_openweather.drop(['visibility','sea_level', 'grnd_level', 'wind_gust', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for the year 2021 to match the sugarbeet data timeframe\n",
    "df_openweather_2021 = df_openweather.query('year == 2021')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes as pickles for next notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sugarbeet.to_pickle('pickles/01_df_sugarbeet.pkl')\n",
    "df_weatherstations.to_pickle('pickles/01_df_weatherstations.pkl')\n",
    "df_locations.to_pickle('pickles/01_df_locations.pkl')\n",
    "df_openweather.to_pickle('pickles/01_df_openweather.pkl')\n",
    "df_openweather_2021.to_pickle('pickles/01_df_openweather_2021.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e059eaba76b2a6e1a2c31f90124418260e93f5f5794c3ff5e8e76706cac962e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
